version: '3.8'

# Production deployment configuration for AI Assistant system
services:
  # Main AI Assistant service
  ai_assistant:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    image: ai_assistant:${TAG:-latest}
    container_name: ai_assistant
    restart: always
    deploy:
      replicas: ${ASSISTANT_REPLICAS:-2}
      resources:
        limits:
          cpus: '4'
          memory: 16G
        reservations:
          cpus: '2'
          memory: 8G
      update_config:
        parallelism: 1
        delay: 10s
        order: start-first
      restart_policy:
        condition: on-failure
        max_attempts: 3
        window: 120s
    ports:
      - "${REST_PORT:-8000}:8000"
      - "${GRPC_PORT:-50051}:50051"
    volumes:
      - ai_models:/data/models
      - ai_knowledge:/data/knowledge_base
      - ai_user_data:/data/user_data
      - ../configs:/app/configs:ro
    environment:
      - ENVIRONMENT=production
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - CONFIG_PATH=/app/configs/environments/production.yaml
      - REDIS_HOST=redis-master
      - REDIS_PORT=6379
      - POSTGRES_HOST=postgres-primary
      - POSTGRES_PORT=5432
      - POSTGRES_USER=${POSTGRES_USER:-ai_assistant}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB:-ai_assistant}
      - VECTOR_DB_HOST=vector-db
      - VECTOR_DB_PORT=6333
      - MODELS_PATH=/data/models
      - CACHE_PATH=/data/cache
      - USER_DATA_PATH=/data/user_data
      - KNOWLEDGE_BASE_PATH=/data/knowledge_base
      - LOG_PATH=/data/logs
      - ENCRYPTION_KEY=${ENCRYPTION_KEY}
      - API_SECRET=${API_SECRET}
      - NODE_ID=${NODE_ID:-primary}
    healthcheck:
      test: ["CMD", "bash", "/app/docker/health-check.sh"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    depends_on:
      redis-master:
        condition: service_healthy
      postgres-primary:
        condition: service_healthy
      vector-db:
        condition: service_healthy
    networks:
      - ai_network
      - ai_monitoring

  # Async worker for background tasks
  ai_worker:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    image: ai_assistant:${TAG:-latest}
    container_name: ai_worker
    restart: always
    deploy:
      replicas: ${WORKER_REPLICAS:-2}
      resources:
        limits:
          cpus: '4'
          memory: 12G
        reservations:
          cpus: '2'
          memory: 6G
    entrypoint: ["python", "-m", "src.cli", "worker"]
    volumes:
      - ai_models:/data/models
      - ai_knowledge:/data/knowledge_base
      - ai_user_data:/data/user_data
      - ../configs:/app/configs:ro
    environment:
      - ENVIRONMENT=production
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - CONFIG_PATH=/app/configs/environments/production.yaml
      - REDIS_HOST=redis-master
      - POSTGRES_HOST=postgres-primary
      - VECTOR_DB_HOST=vector-db
      - ENCRYPTION_KEY=${ENCRYPTION_KEY}
      - WORKER_QUEUE=default
      - WORKER_CONCURRENCY=4
    depends_on:
      - ai_assistant
    networks:
      - ai_network
      - ai_monitoring

  # Redis cluster for caching and messaging
  redis-master:
    image: redis:7-alpine
    container_name: redis-master
    command: redis-server --requirepass ${REDIS_PASSWORD}
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "ping"]
      interval: 5s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
    networks:
      - ai_network

  redis-replica:
    image: redis:7-alpine
    container_name: redis-replica
    command: redis-server --replicaof redis-master 6379 --requirepass ${REDIS_PASSWORD} --masterauth ${REDIS_PASSWORD}
    volumes:
      - redis_replica_data:/data
    depends_on:
      - redis-master
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 2G
    networks:
      - ai_network

  # PostgreSQL database cluster
  postgres-primary:
    image: postgres:15-alpine
    container_name: postgres-primary
    command: postgres -c 'max_connections=200' -c 'shared_buffers=2GB'
    environment:
      - POSTGRES_USER=${POSTGRES_USER:-ai_assistant}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB:-ai_assistant}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ../migrations:/docker-entrypoint-initdb.d:ro
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-ai_assistant}"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 8G
    networks:
      - ai_network

  postgres-replica:
    image: postgres:15-alpine
    container_name: postgres-replica
    environment:
      - POSTGRES_USER=${POSTGRES_USER:-ai_assistant}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB:-ai_assistant}
      - POSTGRES_HOST=postgres-primary
      - POSTGRES_PORT=5432
    volumes:
      - postgres_replica_data:/var/lib/postgresql/data
      - ../scripts/postgres-replica-setup.sh:/docker-entrypoint-initdb.d/setup-replica.sh:ro
    depends_on:
      - postgres-primary
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
    networks:
      - ai_network

  # Vector database for embeddings storage
  vector-db:
    image: qdrant/qdrant:latest
    container_name: vector-db
    volumes:
      - vector_db_data:/qdrant/storage
      - ../configs/vector_db/config.yaml:/qdrant/config/config.yaml:ro
    ports:
      - "6333:6333"
      - "6334:6334"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 8G
    networks:
      - ai_network

  # Monitoring stack
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    volumes:
      - ../infrastructure/monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ../infrastructure/monitoring/prometheus/rules:/etc/prometheus/rules:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
    ports:
      - "9090:9090"
    networks:
      - ai_monitoring

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    volumes:
      - ../infrastructure/monitoring/grafana/datasources:/etc/grafana/provisioning/datasources:ro
      - ../infrastructure/monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - grafana_data:/var/lib/grafana
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
    ports:
      - "3000:3000"
    depends_on:
      - prometheus
    networks:
      - ai_monitoring

  # Logging stack
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.9.0
    container_name: elasticsearch
    environment:
      - node.name=elasticsearch
      - cluster.name=es-docker-cluster
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms4g -Xmx4g"
      - xpack.security.enabled=false
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
    networks:
      - ai_monitoring

  kibana:
    image: docker.elastic.co/kibana/kibana:8.9.0
    container_name: kibana
    environment:
      ELASTICSEARCH_HOSTS: http://elasticsearch:9200
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch
    networks:
      - ai_monitoring

  # Distributed tracing
  jaeger:
    image: jaegertracing/all-in-one:latest
    container_name: jaeger
    environment:
      - COLLECTOR_ZIPKIN_HOST_PORT=:9411
    ports:
      - "5775:5775/udp"
      - "6831:6831/udp"
      - "6832:6832/udp"
      - "5778:5778"
      - "16686:16686"
      - "14268:14268"
      - "14250:14250"
      - "9411:9411"
    networks:
      - ai_monitoring

  # Load balancer for API servers
  nginx:
    image: nginx:alpine
    container_name: nginx
    volumes:
      - ../infrastructure/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ../infrastructure/nginx/conf.d:/etc/nginx/conf.d:ro
      - ../infrastructure/nginx/ssl:/etc/nginx/ssl:ro
    ports:
      - "80:80"
      - "443:443"
    depends_on:
      - ai_assistant
    networks:
      - ai_network

# Network configuration
networks:
  ai_network:
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.28.0.0/16
    name: ai_network
  ai_monitoring:
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.29.0.0/16
    name: ai_monitoring

# Volume configuration
volumes:
  # Application data
  ai_models:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_PATH:-/opt/ai_assistant}/models
  ai_knowledge:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_PATH:-/opt/ai_assistant}/knowledge_base
  ai_user_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_PATH:-/opt/ai_assistant}/user_data
  
  # Database volumes
  redis_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_PATH:-/opt/ai_assistant}/redis/data
  redis_replica_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_PATH:-/opt/ai_assistant}/redis/replica_data
  postgres_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_PATH:-/opt/ai_assistant}/postgres/data
  postgres_replica_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_PATH:-/opt/ai_assistant}/postgres/replica_data
  vector_db_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_PATH:-/opt/ai_assistant}/vector_db
  
  # Monitoring volumes
  prometheus_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_PATH:-/opt/ai_assistant}/prometheus
  grafana_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_PATH:-/opt/ai_assistant}/grafana
  elasticsearch_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_PATH:-/opt/ai_assistant}/elasticsearch
