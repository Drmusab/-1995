# =========================================================
# AI Assistant Model Configurations
# =========================================================
# Author: Drmusab
# Last Modified: 2025-07-05 11:46:08
# Version: 1.0.0
# =========================================================

# Global model settings
global:
  model_registry_path: "${DATA_DIR:-/data/ai_assistant}/models"
  enable_caching: true
  cache_ttl_seconds: 3600
  model_verification: true
  default_timeout_seconds: 30
  auto_fallback: true
  metrics_collection: true
  performance_monitoring: true
  enable_quantization: true
  enable_model_versioning: true
  local_models_directory: "${DATA_DIR:-/data/ai_assistant}/models/local"
  downloaded_models_directory: "${DATA_DIR:-/data/ai_assistant}/models/downloaded"
  fine_tuned_models_directory: "${DATA_DIR:-/data/ai_assistant}/models/fine_tuned"
  model_checkpoints_directory: "${DATA_DIR:-/data/ai_assistant}/models/checkpoints"
  proxy_url: "${MODEL_PROXY_URL:-}"

# Language model configurations
language_models:
  # OpenAI models
  openai:
    enabled: true
    api_base: "${OPENAI_API_BASE:-https://api.openai.com/v1}"
    api_version: "${OPENAI_API_VERSION:-2023-05-15}"
    organization_id: "${OPENAI_ORG_ID:-}"
    models:
      gpt-4:
        model_id: "gpt-4-turbo"
        version: "0726"
        context_window: 128000
        max_output_tokens: 4096
        dimensions: 1536
        capabilities:
          - text_generation
          - summarization
          - translation
          - classification
          - code_generation
          - reasoning
        system_prompt: "You are a helpful, accurate, and expert AI assistant named AI Assistant."
        temperature_presets:
          creative: 0.9
          balanced: 0.7
          precise: 0.2
        top_p: 0.95
        frequency_penalty: 0.0
        presence_penalty: 0.0
        cost_per_1k_tokens:
          input: 0.01
          output: 0.03
        api_type: "chat"
        priority: 1
        tags:
          - "premium"
          - "high_quality"
          - "general_purpose"

      gpt-3.5-turbo:
        model_id: "gpt-3.5-turbo"
        version: "0125"
        context_window: 16385
        max_output_tokens: 4096
        dimensions: 1536
        capabilities:
          - text_generation
          - summarization
          - translation
          - classification
          - code_generation
        system_prompt: "You are a helpful, accurate, and expert AI assistant named AI Assistant."
        temperature_presets:
          creative: 0.9
          balanced: 0.7
          precise: 0.2
        top_p: 0.95
        frequency_penalty: 0.0
        presence_penalty: 0.0
        cost_per_1k_tokens:
          input: 0.0015
          output: 0.002
        api_type: "chat"
        priority: 2
        tags:
          - "standard"
          - "general_purpose"

      text-embedding-3-large:
        model_id: "text-embedding-3-large"
        version: "latest"
        dimensions: 3072
        max_input_tokens: 8191
        capabilities:
          - embeddings
          - semantic_search
        cost_per_1k_tokens: 0.00013
        api_type: "embedding"
        priority: 1
        tags:
          - "embeddings"
          - "high_quality"

      text-embedding-3-small:
        model_id: "text-embedding-3-small"
        version: "latest"
        dimensions: 1536
        max_input_tokens: 8191
        capabilities:
          - embeddings
          - semantic_search
        cost_per_1k_tokens: 0.00002
        api_type: "embedding"
        priority: 2
        tags:
          - "embeddings"
          - "efficient"

      whisper-large-v3:
        model_id: "whisper-large-v3"
        version: "latest"
        capabilities:
          - speech_to_text
          - audio_transcription
          - language_detection
        supported_languages: "all"
        cost_per_minute: 0.006
        api_type: "audio"
        priority: 1
        tags:
          - "audio"
          - "transcription"

  # Ollama models
  ollama:
    enabled: true
    api_base: "${OLLAMA_API_BASE:-http://localhost:11434/api}"
    timeout_seconds: 60
    keep_alive_ms: 5000
    models:
      llama3:
        model_id: "llama3:latest"
        context_window: 8192
        max_output_tokens: 4096
        dimensions: 4096
        capabilities:
          - text_generation
          - summarization
          - translation
          - classification
          - code_generation
          - reasoning
        system_prompt: "You are a helpful, accurate, and expert AI assistant named AI Assistant."
        temperature_presets:
          creative: 0.9
          balanced: 0.7
          precise: 0.2
        top_p: 0.9
        top_k: 40
        gpu_layers: -1  # Use all available
        api_type: "generation"
        priority: 1
        tags:
          - "local"
          - "general_purpose"
          - "offline_capable"

      codellama:
        model_id: "codellama:latest"
        context_window: 16384
        max_output_tokens: 8192
        dimensions: 4096
        capabilities:
          - code_generation
          - code_explanation
          - code_completion
          - debugging
        system_prompt: "You are a coding assistant specialized in software development and programming tasks."
        temperature_presets:
          creative: 0.8
          balanced: 0.5
          precise: 0.1
        top_p: 0.95
        top_k: 40
        gpu_layers: -1
        api_type: "generation"
        priority: 1
        tags:
          - "local"
          - "code_specialized"
          - "offline_capable"

      mistral:
        model_id: "mistral:latest"
        context_window: 8192
        max_output_tokens: 4096
        dimensions: 4096
        capabilities:
          - text_generation
          - summarization
          - translation
          - classification
        system_prompt: "You are a helpful, accurate, and expert AI assistant named AI Assistant."
        temperature_presets:
          creative: 0.9
          balanced: 0.7
          precise: 0.2
        top_p: 0.9
        top_k: 40
        gpu_layers: -1
        api_type: "generation"
        priority: 2
        tags:
          - "local"
          - "general_purpose"
          - "offline_capable"

      orca-mini:
        model_id: "orca-mini:latest"
        context_window: 4096
        max_output_tokens: 2048
        dimensions: 4096
        capabilities:
          - text_generation
          - summarization
          - classification
        system_prompt: "You are a helpful AI assistant."
        temperature_presets:
          creative: 0.9
          balanced: 0.7
          precise: 0.2
        top_p: 0.9
        top_k: 40
        gpu_layers: 0  # CPU only
        api_type: "generation"
        priority: 3
        tags:
          - "local"
          - "lightweight"
          - "cpu_optimized"
          - "offline_capable"

      nomic-embed:
        model_id: "nomic-embed-text:latest"
        dimensions: 768
        max_input_tokens: 8192
        capabilities:
          - embeddings
          - semantic_search
        gpu_layers: 0  # CPU only
        api_type: "embedding"
        priority: 2
        tags:
          - "local"
          - "embeddings"
          - "offline_capable"

  # Deepseek models
  deepseek:
    enabled: true
    api_base: "${DEEPSEEK_API_BASE:-https://api.deepseek.com/v1}"
    api_version: "${DEEPSEEK_API_VERSION:-v1}"
    models:
      deepseek-chat:
        model_id: "deepseek-chat"
        version: "latest"
        context_window: 8192
        max_output_tokens: 4096
        dimensions: 1024
        capabilities:
          - text_generation
          - summarization
          - translation
          - code_generation
        system_prompt: "You are a helpful, accurate, and expert AI assistant named AI Assistant."
        temperature_presets:
          creative: 0.9
          balanced: 0.7
          precise: 0.2
        top_p: 0.95
        frequency_penalty: 0.0
        presence_penalty: 0.0
        api_type: "chat"
        priority: 2
        tags:
          - "alternative"
          - "general_purpose"

      deepseek-coder:
        model_id: "deepseek-coder"
        version: "latest"
        context_window: 16384
        max_output_tokens: 8192
        dimensions: 1024
        capabilities:
          - code_generation
          - code_explanation
          - code_completion
          - debugging
        system_prompt: "You are an expert programming assistant specialized in writing and explaining code."
        temperature_presets:
          creative: 0.8
          balanced: 0.5
          precise: 0.1
        top_p: 0.95
        frequency_penalty: 0.0
        presence_penalty: 0.0
        api_type: "chat"
        priority: 1
        tags:
          - "alternative"
          - "code_specialized"

# Embedding model configurations
embedding_models:
  default: "text-embedding-3-small"
  sentence_transformers:
    enabled: true
    models:
      all-mpnet-base-v2:
        model_id: "all-mpnet-base-v2"
        dimensions: 768
        max_input_tokens: 512
        capabilities:
          - embeddings
          - semantic_search
          - clustering
        normalize_embeddings: true
        model_location: "local"
        quantization: "int8"
        device: "auto"
        batch_size: 32
        priority: 2
        tags:
          - "local"
          - "embeddings"
          - "multilingual"
          - "offline_capable"

      all-MiniLM-L6-v2:
        model_id: "all-MiniLM-L6-v2"
        dimensions: 384
        max_input_tokens: 256
        capabilities:
          - embeddings
          - semantic_search
          - clustering
        normalize_embeddings: true
        model_location: "local"
        quantization: "int8"
        device: "auto"
        batch_size: 64
        priority: 3
        tags:
          - "local"
          - "embeddings"
          - "lightweight"
          - "cpu_optimized"
          - "offline_capable"

  faiss:
    enabled: true
    index_type: "IVFFlat"
    nlist: 100
    nprobe: 10
    metric: "cosine"
    use_gpu: "${USE_GPU:-false}"
    store_on_disk: true
    index_directory: "${DATA_DIR:-/data/ai_assistant}/vector_indices"

# Speech models configuration
speech_models:
  text_to_speech:
    default: "elevenlabs_multilingual"
    models:
      elevenlabs_multilingual:
        model_id: "eleven_multilingual_v2"
        provider: "elevenlabs"
        api_key: "${ELEVENLABS_API_KEY}"
        capabilities:
          - text_to_speech
          - voice_cloning
        supported_languages:
          - "en"
          - "es"
          - "fr"
          - "de"
          - "it"
          - "pt"
          - "pl"
          - "hi"
          - "ar"
          - "zh"
          - "ja"
        voice_settings:
          stability: 0.7
          similarity_boost: 0.5
          style: 0.0
          use_speaker_boost: true
        sample_rate: 24000
        formats: ["mp3", "wav", "ogg", "pcm"]
        priority: 1
        tags:
          - "high_quality"
          - "multilingual"
          - "natural"

      openai_tts:
        model_id: "tts-1"
        provider: "openai"
        capabilities:
          - text_to_speech
        supported_languages:
          - "en"
        voice_options:
          - "alloy"
          - "echo"
          - "fable"
          - "onyx"
          - "nova"
          - "shimmer"
        default_voice: "nova"
        sample_rate: 24000
        formats: ["mp3", "opus", "aac", "pcm"]
        priority: 2
        tags:
          - "cloud_based"
          - "high_quality"

      local_piper:
        model_id: "piper-tts"
        provider: "local"
        model_path: "${DATA_DIR:-/data/ai_assistant}/models/speech/piper"
        capabilities:
          - text_to_speech
        supported_languages:
          - "en"
          - "es"
          - "fr"
          - "de"
          - "it"
        voice_options:
          - "en_US/vctk_low"
          - "en_US/ljspeech_low"
          - "es_ES/carlfm_low"
        default_voice: "en_US/ljspeech_low"
        sample_rate: 22050
        formats: ["wav", "mp3"]
        device: "auto"
        priority: 3
        tags:
          - "local"
          - "offline_capable"
          - "lightweight"

  speech_to_text:
    default: "openai_whisper"
    models:
      openai_whisper:
        model_id: "whisper-large-v3"
        provider: "openai"
        capabilities:
          - speech_to_text
          - audio_transcription
          - language_detection
        supported_languages: "all"
        detect_language: true
        temperature: 0.0
        response_formats: ["json", "text", "srt", "vtt"]
        translate_to_english: false
        priority: 1
        tags:
          - "cloud_based"
          - "high_accuracy"

      local_whisper:
        model_id: "whisper-medium.en"
        provider: "local"
        model_path: "${DATA_DIR:-/data/ai_assistant}/models/speech/whisper"
        capabilities:
          - speech_to_text
          - audio_transcription
        supported_languages: ["en"]
        compute_type: "int8"
        device: "auto"
        beam_size: 5
        temperature: 0.0
        priority: 2
        tags:
          - "local"
          - "offline_capable"
          - "english_only"

      local_vosk:
        model_id: "vosk-model-small-en-us-0.15"
        provider: "local"
        model_path: "${DATA_DIR:-/data/ai_assistant}/models/speech/vosk"
        capabilities:
          - speech_to_text
          - audio_transcription
        supported_languages: ["en"]
        sample_rate: 16000
        device: "cpu"
        priority: 3
        tags:
          - "local"
          - "offline_capable"
          - "lightweight"
          - "realtime"

  speaker_recognition:
    default: "speechbrain_spkrec"
    models:
      speechbrain_spkrec:
        model_id: "speechbrain-spkrec-ecapa-voxceleb"
        provider: "local"
        model_path: "${DATA_DIR:-/data/ai_assistant}/models/speech/speaker_recognition"
        capabilities:
          - speaker_identification
          - speaker_verification
          - speaker_diarization
        embedding_dim: 192
        threshold: 0.75
        device: "auto"
        priority: 1
        tags:
          - "local"
          - "offline_capable"

  emotion_detection:
    default: "speechbrain_emotion"
    models:
      speechbrain_emotion:
        model_id: "speechbrain-emotion-recognition"
        provider: "local"
        model_path: "${DATA_DIR:-/data/ai_assistant}/models/speech/emotion"
        capabilities:
          - emotion_detection
        emotions:
          - "neutral"
          - "happy"
          - "sad"
          - "angry"
          - "fearful"
          - "disgusted"
          - "surprised"
        device: "auto"
        priority: 1
        tags:
          - "local"
          - "offline_capable"

# Vision models configuration
vision_models:
  object_detection:
    default: "yolo_v8"
    models:
      yolo_v8:
        model_id: "yolov8n.pt"
        provider: "local"
        model_path: "${DATA_DIR:-/data/ai_assistant}/models/vision/yolo"
        capabilities:
          - object_detection
          - object_classification
        classes: 80  # COCO dataset classes
        confidence_threshold: 0.25
        nms_threshold: 0.45
        device: "auto"
        quantization: "int8"
        image_size: 640
        priority: 1
        tags:
          - "local"
          - "offline_capable"
          - "realtime"

  image_classification:
    default: "efficientnet_b0"
    models:
      efficientnet_b0:
        model_id: "efficientnet_b0"
        provider: "local"
        model_path: "${DATA_DIR:-/data/ai_assistant}/models/vision/classification"
        capabilities:
          - image_classification
        classes: 1000  # ImageNet classes
        confidence_threshold: 0.5
        device: "auto"
        quantization: "int8"
        image_size: 224
        priority: 1
        tags:
          - "local"
          - "offline_capable"
          - "lightweight"

  face_recognition:
    default: "face_recognition"
    models:
      face_recognition:
        model_id: "dlib_face_recognition_resnet_model_v1"
        provider: "local"
        model_path: "${DATA_DIR:-/data/ai_assistant}/models/vision/face"
        capabilities:
          - face_detection
          - face_recognition
          - face_landmarks
        num_jitters: 1
        face_distance_threshold: 0.6
        device: "cpu"
        priority: 1
        tags:
          - "local"
          - "offline_capable"

  optical_character_recognition:
    default: "tesseract"
    models:
      tesseract:
        model_id: "tesseract-ocr-4.1.1"
        provider: "local"
        model_path: "${DATA_DIR:-/data/ai_assistant}/models/vision/ocr"
        capabilities:
          - text_recognition
          - document_analysis
        languages:
          - "eng"
          - "spa"
          - "fra"
          - "deu"
          - "ita"
          - "por"
          - "ara"
          - "rus"
          - "jpn"
          - "chi_sim"
        page_segmentation_mode: 3  # Auto page segmentation, but no OSD
        ocr_engine_mode: 2  # Legacy + LSTM
        priority: 1
        tags:
          - "local"
          - "offline_capable"
          - "multilingual"

  pose_estimation:
    default: "mediapipe_pose"
    models:
      mediapipe_pose:
        model_id: "mediapipe-pose"
        provider: "local"
        model_path: "${DATA_DIR:-/data/ai_assistant}/models/vision/pose"
        capabilities:
          - pose_estimation
          - body_tracking
        min_detection_confidence: 0.5
        min_tracking_confidence: 0.5
        static_image_mode: false
        model_complexity: 1  # 0, 1, or 2
        device: "auto"
        priority: 1
        tags:
          - "local"
          - "offline_capable"
          - "realtime"

# Multimodal model configurations
multimodal_models:
  default: "openai_gpt4v"
  models:
    openai_gpt4v:
      model_id: "gpt-4-vision-preview"
      provider: "openai"
      capabilities:
        - image_understanding
        - visual_reasoning
        - multimodal_conversation
      context_window: 128000
      max_output_tokens: 4096
      max_image_tokens: 65536  # Approx tokens for image content
      image_detail: "high"  # auto, low, high
      temperature: 0.7
      supported_image_formats:
        - "png"
        - "jpeg"
        - "jpg"
        - "webp"
        - "gif"
      max_images_per_request: 20
      max_image_size_mb: 20
      priority: 1
      tags:
        - "cloud_based"
        - "high_quality"

    local_llava:
      model_id: "llava-1.6-mistral-7b"
      provider: "ollama"
      capabilities:
        - image_understanding
        - visual_reasoning
        - multimodal_conversation
      context_window: 4096
      max_output_tokens: 1024
      temperature: 0.7
      top_p: 0.9
      gpu_layers: -1
      supported_image_formats:
        - "png"
        - "jpeg"
        - "jpg"
      max_images_per_request: 1
      max_image_size_mb: 10
      priority: 2
      tags:
        - "local"
        - "offline_capable"

# Special purpose models
special_purpose_models:
  recommendation:
    default: "collaborative_filtering"
    models:
      collaborative_filtering:
        model_id: "implicit-als"
        provider: "local"
        model_path: "${DATA_DIR:-/data/ai_assistant}/models/special/recommendation"
        capabilities:
          - user_recommendations
          - item_recommendations
          - similarity_calculation
        factors: 128
        iterations: 15
        regularization: 0.01
        alpha: 40
        priority: 1
        tags:
          - "local"
          - "offline_capable"

  sentiment_analysis:
    default: "distilbert_sentiment"
    models:
      distilbert_sentiment:
        model_id: "distilbert-base-uncased-finetuned-sst-2-english"
        provider: "local"
        model_path: "${DATA_DIR:-/data/ai_assistant}/models/special/sentiment"
        capabilities:
          - sentiment_analysis
          - emotion_detection
        classes:
          - "positive"
          - "negative"
        device: "auto"
        quantization: "int8"
        priority: 1
        tags:
          - "local"
          - "offline_capable"
          - "lightweight"

  entity_extraction:
    default: "spacy_ner"
    models:
      spacy_ner:
        model_id: "en_core_web_trf"
        provider: "local"
        model_path: "${DATA_DIR:-/data/ai_assistant}/models/special/ner"
        capabilities:
          - named_entity_recognition
          - part_of_speech_tagging
          - dependency_parsing
        supported_languages: ["en"]
        device: "auto"
        priority: 1
        tags:
          - "local"
          - "offline_capable"
          - "nlp"

# Model selection strategies
model_selection_strategies:
  default: "quality_first"
  strategies:
    quality_first:
      description: "Prioritizes model quality and capabilities over performance and cost"
      selection_criteria:
        - capability_match: 10
        - quality_score: 8
        - response_time: 2
        - cost: 1
      fallback_strategy: "balanced"

    performance_first:
      description: "Prioritizes fast response times over quality"
      selection_criteria:
        - capability_match: 10
        - response_time: 8
        - quality_score: 3
        - cost: 5
      fallback_strategy: "balanced"

    cost_effective:
      description: "Prioritizes lower cost models when possible"
      selection_criteria:
        - capability_match: 10
        - cost: 8
        - quality_score: 4
        - response_time: 4
      fallback_strategy: "balanced"

    balanced:
      description: "Balances quality, performance and cost"
      selection_criteria:
        - capability_match: 10
        - quality_score: 5
        - response_time: 5
        - cost: 5
      fallback_strategy: "offline_capable"

    offline_capable:
      description: "Prioritizes models that can work without internet connection"
      selection_criteria:
        - capability_match: 10
        - offline_capability: 10
        - quality_score: 5
        - response_time: 5
      fallback_strategy: "quality_first"

    smart:
      description: "Dynamically selects models based on task complexity and requirements"
      dynamic: true
      evaluation_factors:
        - input_complexity
        - input_length
        - required_capabilities
        - expected_output_quality
        - response_time_requirement
        - available_compute
        - cost_constraints
      fallback_strategy: "balanced"

# Environment-specific overrides
environment_overrides:
  development:
    default_strategy: "offline_capable"
    preferred_providers:
      - "ollama"
      - "local"
    enable_model_mocking: true
    default_language_model: "ollama/mistral"
    default_embedding_model: "sentence_transformers/all-MiniLM-L6-v2"
    model_verification: false
    
  staging:
    default_strategy: "balanced"
    preferred_providers:
      - "openai"
      - "ollama"
    enable_model_mocking: false
    default_language_model: "openai/gpt-3.5-turbo"
    default_embedding_model: "openai/text-embedding-3-small"
    model_verification: true
    
  production:
    default_strategy: "smart"
    preferred_providers:
      - "openai"
      - "deepseek"
    enable_model_mocking: false
    default_language_model: "openai/gpt-4"
    default_embedding_model: "openai/text-embedding-3-large"
    model_verification: true
    performance_monitoring: true
    metrics_collection: true
