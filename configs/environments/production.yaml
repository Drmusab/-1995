# =========================================================
# AI Assistant Production Configuration
# =========================================================
# Author: Drmusab
# Last Modified: 2025-07-05 11:40:54
# Environment: Production
# =========================================================

# Environment settings
environment:
  name: "production"
  debug: false
  verbose_logging: false
  hot_reload: false
  development_mode: false
  local_execution: false

# Core system settings
system:
  version: "1.0.0"
  instance_id: "${HOSTNAME}-${POD_NAME}"
  max_concurrent_tasks: 100
  timezone: "UTC"
  temp_directory: "/tmp/ai_assistant"
  data_directory: "/data/ai_assistant"
  startup_timeout: 120  # seconds
  shutdown_timeout: 90  # seconds
  auto_recovery: true
  graceful_shutdown: true

# Core engine configuration
core_engine:
  default_processing_mode: "asynchronous"
  max_concurrent_requests: 200
  default_timeout_seconds: 30.0
  enable_real_time_processing: true
  enable_speech_processing: true
  enable_vision_processing: true
  enable_multimodal_fusion: true
  enable_reasoning: true
  enable_learning: true
  default_quality_level: "balanced"
  adaptive_quality: true
  quality_monitoring: true
  working_memory_size: 8000
  context_window_size: 16384
  memory_consolidation_interval: 600  # 10 minutes
  enable_response_caching: true
  enable_component_caching: true
  cache_ttl_seconds: 1200  # 20 minutes
  require_authentication: true
  enable_authorization: true
  audit_logging: true
  enable_performance_monitoring: true
  enable_profiling: false
  gc_interval_seconds: 300

# Component manager configuration
component_manager:
  auto_discovery: false  # Explicit component registration in production
  parallel_initialization: true
  health_monitoring: true
  health_check_interval: 30
  auto_restart_failed: true
  max_restart_attempts: 5
  restart_backoff_factor: 2.0
  component_directories:
    - "/app/src/processing"
    - "/app/src/integrations"
    - "/app/src/memory"
    - "/app/src/skills"
    - "/app/src/reasoning"

# Plugin manager configuration
plugins:
  enabled: true
  auto_discovery: false  # Explicit plugin registration in production
  auto_discovery_interval: 0  # Disabled in production
  directories:
    - "/data/ai_assistant/plugins"
  hot_reload: false
  security_validation: true
  max_plugins_per_type: 50
  plugin_timeout: 30
  plugin_memory_limit_mb: 1024
  default_security_level: "sandbox"

# Session manager configuration
sessions:
  storage_type: "database"
  max_idle_time: 1200.0  # 20 minutes
  max_session_time: 86400.0  # 24 hours
  cleanup_on_expire: true
  persist_context: true
  enable_clustering: true
  auto_save_interval: 180.0  # 3 minutes
  encryption_enabled: true
  audit_logging: true
  max_sessions_per_node: 5000
  node_id: "${HOSTNAME}-${POD_NAME}"

# Workflow orchestrator configuration
workflows:
  enabled: true
  workflow_directory: "/data/ai_assistant/workflows"
  max_concurrent_workflows: 100
  default_timeout: 300  # seconds
  auto_retry_failed: true
  max_retries: 3
  retry_delay: 5  # seconds
  auto_cleanup_completed: true
  max_workflow_history: 1000
  auto_generated_workflows: true
  workflow_templates:
    - "conversation"
    - "research"
    - "content_creation"
    - "data_analysis"
    - "customer_support"
    - "onboarding"
    - "system_maintenance"
    - "error_recovery"

# Interactions configuration
interactions:
  max_duration: 1800  # 30 minutes
  default_timeout: 120  # 2 minutes
  enable_real_time: true
  enable_streaming: true
  max_conversation_history: 500
  default_interaction_mode: "conversational"
  default_input_modalities:
    - "text"
  default_output_modalities:
    - "text"
  auto_detect_modalities: true
  save_interaction_history: true

# Integration configurations
integrations:
  # LLM providers
  llm:
    default_provider: "openai"  # ollama, openai, deepseek
    model_router:
      enabled: true
      strategy: "smart"  # cost_effective, performance, quality, balanced, smart
      timeout: 30  # seconds
      auto_fallback: true
    ollama:
      enabled: true
      endpoint: "http://ollama-service.llm.svc.cluster.local:11434"
      models:
        - name: "llama3"
          context_size: 8192
          default: false
        - name: "mistral"
          context_size: 4096
          default: false
        - name: "codellama"
          context_size: 16384
      timeout: 60
    openai:
      enabled: true
      api_key: "${OPENAI_API_KEY}"
      organization_id: "${OPENAI_ORG_ID}"
      models:
        - name: "gpt-4"
          context_size: 8192
          default: true
        - name: "gpt-3.5-turbo"
          context_size: 4096
          default: false
      timeout: 60
    deepseek:
      enabled: true
      api_key: "${DEEPSEEK_API_KEY}"
      models:
        - name: "deepseek-chat"
          context_size: 4096
          default: false
      timeout: 60

  # Cache configuration
  cache:
    strategy: "redis"  # local, redis, hybrid
    ttl: 1200  # 20 minutes
    max_size_mb: 8192
    enable_compression: true
    redis:
      enabled: true
      host: "redis-cache.cache.svc.cluster.local"
      port: 6379
      password: "${REDIS_PASSWORD}"
      db: 0
      key_prefix: "ai_assistant_prod"
      sentinel:
        enabled: true
        master_name: "mymaster"
        sentinel_hosts:
          - "redis-sentinel-0.redis.svc.cluster.local:26379"
          - "redis-sentinel-1.redis.svc.cluster.local:26379" 
          - "redis-sentinel-2.redis.svc.cluster.local:26379"
      cluster:
        enabled: true
        nodes:
          - "redis-cluster-0.redis.svc.cluster.local:6379"
          - "redis-cluster-1.redis.svc.cluster.local:6379"
          - "redis-cluster-2.redis.svc.cluster.local:6379"
    local:
      enabled: false
      directory: "/data/ai_assistant/cache"
      max_entries: 100000
      eviction_policy: "lru"  # lru, lfu, fifo

  # Database configuration
  database:
    enabled: true
    type: "postgres"  # sqlite, postgres
    sqlite:
      path: "/data/ai_assistant/database/production.db"
    postgres:
      host: "postgres-primary.db.svc.cluster.local"
      port: 5432
      username: "aiassistant"
      password: "${DB_PASSWORD}"
      database: "aiassistant_production"
      replica_hosts:
        - "postgres-replica-0.db.svc.cluster.local"
        - "postgres-replica-1.db.svc.cluster.local"
      ssl_mode: "verify-full"
      ssl_cert: "/etc/ssl/certs/postgres-client.crt"
      ssl_key: "/etc/ssl/private/postgres-client.key"
      ssl_root_cert: "/etc/ssl/certs/postgres-ca.crt"
    connection_pool: 50
    timeout: 30
    auto_migrate: false  # Migrations should be run explicitly in production
    connection_max_age: 300  # 5 minutes
    retry_on_failure: true
    max_retries: 3
    retry_delay: 2  # seconds

  # External APIs
  external_apis:
    web_search:
      enabled: true
      provider: "google"  # dummy, bing, google
      api_key: "${SEARCH_API_KEY}"
      results_per_query: 10
      timeout: 15
      backup_provider: "bing"
      backup_api_key: "${BING_API_KEY}"
    weather:
      enabled: true
      provider: "openweathermap"  # dummy, openweathermap
      api_key: "${WEATHER_API_KEY}"
      timeout: 10
      cache_results: true
      cache_ttl: 1800  # 30 minutes
    calendar:
      enabled: true
      provider: "google"  # dummy, google
      client_id: "${CALENDAR_CLIENT_ID}"
      client_secret: "${CALENDAR_CLIENT_SECRET}"
      timeout: 15

# API configurations
api:
  enabled: true
  # REST API configuration
  rest:
    enabled: true
    host: "0.0.0.0"
    port: 8000
    debug: false
    prefix: "/api/v1"
    swagger: false  # Disabled in production
    middleware:
      cors:
        enabled: true
        allow_origins: ["https://*.example.com", "https://app.example.com"]
        allow_methods: ["GET", "POST", "PUT", "DELETE", "OPTIONS"]
      rate_limiter:
        enabled: true
        max_requests: 100
        window_seconds: 60
        per_user: true
        override_roles:
          admin: 1000
          premium: 300
        response_code: 429
        storage: "redis"
      compression:
        enabled: true
        level: 6
        min_size: 1024
        types: ["text/html", "text/css", "application/javascript", "application/json"]
      auth:
        enabled: true
        jwt_secret: "${JWT_SECRET}"
        token_expiry: 86400  # 24 hours
        refresh_token_expiry: 2592000  # 30 days
        cookie_secure: true
        cookie_http_only: true
        cookie_same_site: "strict"
        allowed_algorithms: ["HS256", "RS256"]
        public_key_path: "/etc/ssl/certs/jwt-public.pem"
        private_key_path: "/etc/ssl/private/jwt-private.pem"

  # WebSocket API configuration
  websocket:
    enabled: true
    host: "0.0.0.0"
    port: 8001
    path: "/ws"
    heartbeat_interval: 30
    max_connections: 10000
    max_message_size: 1048576  # 1MB
    auth_required: true
    connection_timeout: 60
    compression_enabled: true
    ping_timeout: 30
    close_timeout: 10

  # GraphQL API configuration
  graphql:
    enabled: true
    host: "0.0.0.0"
    port: 8002
    path: "/graphql"
    playground: false  # Disabled in production
    debug: false
    introspection: false  # Disabled in production
    batch_enabled: true
    complexity_limit: 1000
    depth_limit: 10
    rate_limit:
      enabled: true
      max_requests: 300
      window_seconds: 60

  # gRPC API configuration
  grpc:
    enabled: true
    host: "0.0.0.0"
    port: 50051
    max_workers: 50
    reflection: false  # Disabled in production
    max_concurrent_rpcs: 100
    keepalive_time_ms: 7200000  # 2 hours
    keepalive_timeout_ms: 20000  # 20 seconds
    connection_timeout_ms: 5000  # 5 seconds
    max_connection_age_ms: 300000  # 5 minutes
    max_connection_idle_ms: 600000  # 10 minutes

# Memory configurations
memory:
  vector_store:
    type: "postgres"  # local, redis, postgres
    dimension: 1536
    metric: "cosine"  # cosine, euclidean, dot
    index_path: "/data/ai_assistant/vector_indices"
    sharding:
      enabled: true
      shards: 3
  working_memory:
    max_size: 8000
    ttl_seconds: 1800
    priority_queuing: true
  episodic_memory:
    max_episodes: 1000000
    consolidation_interval: 1800  # 30 minutes
    long_term_storage: true
  semantic_memory:
    enabled: true
    auto_learn: true
    update_frequency: "daily"
  context_window:
    size: 16384
    overlap: 200
    adaptive_sizing: true
  cache:
    enabled: true
    ttl_seconds: 1200
    max_size_mb: 4096
    distributed: true

# Skills configurations
skills:
  auto_discovery: false  # Explicitly register skills in production
  skill_directories:
    - "/app/src/skills/builtin"
    - "/app/src/skills/custom"
    - "/data/ai_assistant/skills"
  validate_skills: true
  skill_timeout: 30
  max_skill_memory_mb: 768
  composition:
    enabled: true
    max_composition_depth: 8
  development_mode: false
  default_skills:
    - "conversation"
    - "search"
    - "calculator"
    - "summarization"
    - "translation"
    - "knowledge_base"
    - "content_generation"
    - "data_visualization"
    - "document_processing"
    - "task_automation"

# Processing configurations
processing:
  # Natural language processing
  natural_language:
    default_language: "en"
    intent_threshold: 0.8
    sentiment_analysis: true
    entity_extraction: true
    language_detection: true
    tokenizer: "default"
    max_tokens: 16384
    languages_supported:
      - "en"
      - "es"
      - "fr"
      - "de"
      - "zh"
      - "ja"
      - "ar"
      - "ru"
    custom_entities:
      enabled: true
      path: "/data/ai_assistant/custom_entities"

  # Speech processing
  speech:
    enabled: true
    default_quality: "quality"  # fast, balanced, quality
    model_path: "/data/ai_assistant/models/speech"
    audio_sample_rate: 16000
    use_gpu: true
    emotion_detection: true
    speaker_recognition: true
    cache_transcriptions: true
    noise_reduction: true
    silence_removal: true
    languages_supported:
      - "en-US"
      - "en-GB"
      - "es-ES"
      - "fr-FR"
      - "de-DE"
      - "zh-CN"
      - "ja-JP"

  # Vision processing
  vision:
    enabled: true
    model_path: "/data/ai_assistant/models/vision"
    default_resolution: "high"  # low, medium, high
    use_gpu: true
    detect_faces: true
    detect_objects: true
    ocr_enabled: true
    cache_results: true
    unsafe_content_detection: true
    max_image_size_mb: 10
    supported_formats:
      - "jpg"
      - "jpeg"
      - "png"
      - "gif"
      - "webp"
      - "bmp"

  # Multimodal processing
  multimodal:
    enabled: true
    fusion_strategy: "attention"  # early, late, weighted, attention
    cross_modal_attention: true
    modality_weights:
      text: 0.5
      speech: 0.3
      vision: 0.2
    context_preservation: true
    unified_encoding: true

# Reasoning configurations
reasoning:
  enabled: true
  logic_engine:
    max_depth: 10
    timeout: 30
    uncertainty_handling: true
  knowledge_graph:
    enabled: true
    path: "/data/ai_assistant/knowledge_base/graphs"
    auto_update: true
    reasoning_strategies:
      - "deductive"
      - "inductive"
      - "abductive"
    inference_engine:
      max_rules: 1000
      timeout: 45
  planning:
    enabled: true
    max_steps: 20
    goal_decomposition: true
    alternative_plans: 3
    plan_validation: true
  decision_making:
    confidence_threshold: 0.85
    uncertainty_handling: true
    decision_tree:
      max_depth: 10
    fallback_strategies:
      - "ask_clarification"
      - "suggest_alternatives"
      - "escalate_to_human"

# Learning configurations
learning:
  enabled: true
  continual_learning:
    enabled: true
    update_interval: 14400  # 4 hours
    batch_size: 256
    learning_rate: 0.0005
    regularization: true
    data_retention_days: 90
  preference_learning:
    enabled: true
    adaptation_rate: 0.1
    user_preference_models: true
    personalization_level: "medium"  # low, medium, high
  feedback_processing:
    enabled: true
    incorporate_feedback: true
    feedback_types:
      - "explicit"
      - "implicit"
      - "behavioral"
    weight_recent_feedback: true
  model_adaptation:
    enabled: true
    fine_tuning: true
    evaluation_metrics:
      - "accuracy"
      - "relevance"
      - "helpfulness"
      - "safety"
    schedule: "weekly"

# Observability configurations
observability:
  # Logging
  logging:
    level: "INFO"
    format: "json"
    console_output: false
    file_output: true
    log_directory: "/var/log/ai_assistant"
    max_log_size_mb: 1000
    max_log_files: 60
    trace_enabled: true
    sanitize_sensitive_data: true
    forward_to_elk: true
    elk:
      host: "elasticsearch.logging.svc.cluster.local"
      port: 9200
      username: "${ELK_USERNAME}"
      password: "${ELK_PASSWORD}"
      index_prefix: "ai-assistant-prod"
    custom_handlers:
      rotation:
        enabled: true
        when: "midnight"
        interval: 1
        backup_count: 30
      cloud_watch:
        enabled: true
        group: "ai-assistant-production"
        stream: "application-logs"

  # Monitoring
  monitoring:
    enabled: true
    metrics:
      enabled: true
      export: true
      port: 8003
      path: "/metrics"
      prometheus:
        enabled: true
        push_gateway: "prometheus-pushgateway.monitoring.svc.cluster.local:9091"
        job_name: "ai-assistant"
        push_interval: 15
      statsd:
        enabled: true
        host: "statsd.monitoring.svc.cluster.local"
        port: 8125
        prefix: "ai_assistant"
    tracing:
      enabled: true
      exporter: "jaeger"
      jaeger_endpoint: "http://jaeger-collector.tracing.svc.cluster.local:14268/api/traces"
      sampling_rate: 0.1
      trace_id_ratio: 0.1
      propagation_formats:
        - "b3"
        - "w3c"
      send_hostname: true
    alerting:
      enabled: true
      threshold_cpu_percent: 85
      threshold_memory_percent: 85
      threshold_error_rate: 0.02
      threshold_latency_ms: 500
      alert_channels:
        - "slack"
        - "pagerduty"
        - "email"
      pagerduty_key: "${PAGERDUTY_KEY}"
      slack_webhook: "${SLACK_WEBHOOK}"
      alert_email: "alerts@example.com"
    dashboards:
      enabled: true
      refresh_interval: 60
      grafana:
        url: "https://grafana.example.com"
        org_id: 1
        folder: "AI Assistant"

  # Profiling
  profiling:
    enabled: false  # Disabled in production by default
    cpu_profiling: false
    memory_profiling: false
    gpu_profiling: false
    profile_directory: "/var/lib/ai_assistant/profiles"
    interval: 3600  # 1 hour
    trigger_on_high_load: true
    high_load_threshold_cpu: 90
    high_load_threshold_memory: 90

# Security configurations
security:
  # Authentication
  authentication:
    enabled: true
    providers:
      - "oauth"
      - "saml"
      - "local"
    local:
      user_db_path: "/data/ai_assistant/users.db"
      password_hash_algorithm: "bcrypt"
      password_hash_rounds: 12
      password_min_length: 12
      require_special_chars: true
      require_numbers: true
      require_mixed_case: true
    oauth:
      google:
        enabled: true
        client_id: "${GOOGLE_OAUTH_CLIENT_ID}"
        client_secret: "${GOOGLE_OAUTH_CLIENT_SECRET}"
      github:
        enabled: true
        client_id: "${GITHUB_OAUTH_CLIENT_ID}"
        client_secret: "${GITHUB_OAUTH_CLIENT_SECRET}"
      microsoft:
        enabled: true
        client_id: "${MS_OAUTH_CLIENT_ID}"
        client_secret: "${MS_OAUTH_CLIENT_SECRET}"
    saml:
      enabled: true
      idp_metadata_url: "https://idp.example.com/metadata.xml"
      sp_entity_id: "ai-assistant-prod"
      acs_url: "https://ai.example.com/saml/callback"
      attribute_mapping:
        email: "http://schemas.xmlsoap.org/ws/2005/05/identity/claims/emailaddress"
        name: "http://schemas.xmlsoap.org/ws/2005/05/identity/claims/name"
        groups: "http://schemas.xmlsoap.org/claims/Group"
    mfa:
      enabled: true
      required_for_roles:
        - "admin"
        - "operator"
      methods:
        - "totp"
        - "backup_codes"
    session_timeout: 43200  # 12 hours
    max_failed_attempts: 5
    lockout_duration: 1800  # 30 minutes
    token_secret: "${JWT_SECRET}"
    secure_headers: true

  # Authorization
  authorization:
    enabled: true
    rbac_enabled: true
    default_role: "user"
    roles:
      - name: "admin"
        permissions: ["*"]
      - name: "operator"
        permissions: ["read:*", "write:*", "execute:*", "manage:workflows"]
      - name: "user"
        permissions: ["read:basic", "execute:skills", "create:data"]
      - name: "guest"
        permissions: ["read:public"]
    attribute_based:
      enabled: true
      attributes:
        - "department"
        - "location"
        - "clearance_level"
    permission_validation: true

  # Encryption
  encryption:
    enabled: true
    algorithm: "AES-256-GCM"
    key_rotation: true
    key_rotation_interval: 30  # days
    key_path: "/etc/ai_assistant/keys"
    encrypt_at_rest: true
    encrypt_in_transit: true
    key_management:
      provider: "vault"  # vault, aws-kms, azure-key-vault
      vault:
        address: "https://vault.security.svc.cluster.local:8200"
        token_path: "/etc/vault/token"
        key_path: "secret/data/ai-assistant/encryption-keys"

  # Sanitization
  sanitization:
    enabled: true
    sanitize_inputs: true
    sanitize_outputs: true
    allowed_html_tags: ["b", "i", "code", "pre", "a", "ul", "ol", "li", "p", "br", "span", "div", "h1", "h2", "h3", "h4", "h5", "h6"]
    content_security_policy: true
    xss_protection: true
    sql_injection_protection: true
    content_filtering:
      enabled: true
      profanity_filter: true
      pii_detection: true
      sensitive_data_detection: true

# High availability and scaling
high_availability:
  enabled: true
  cluster_mode: true
  node_discovery:
    enabled: true
    method: "kubernetes"  # kubernetes, consul, static
    kubernetes:
      namespace: "ai-assistant"
      service_name: "ai-assistant-api"
      label_selector: "app=ai-assistant,component=api"
    consul:
      address: "consul.service.consul:8500"
      service_name: "ai-assistant"
      data_center: "dc1"
  leader_election:
    enabled: true
    lease_duration: 15  # seconds
    renew_deadline: 10  # seconds
    retry_period: 2    # seconds
  load_balancing:
    strategy: "least_connections"  # round_robin, least_connections, consistent_hash
    sticky_sessions: true
    session_affinity_key: "user_id"
  fault_tolerance:
    circuit_breaker:
      enabled: true
      error_threshold_percentage: 50
      request_volume_threshold: 20
      sleep_window_ms: 5000
    retry:
      enabled: true
      max_attempts: 3
      backoff_multiplier: 1.5
    timeout:
      enabled: true
      default_ms: 30000
      connect_ms: 5000
    bulkhead:
      enabled: true
      max_concurrent_calls: 100
      max_wait_duration_ms: 1000
  disaster_recovery:
    backup:
      enabled: true
      schedule: "0 2 * * *"  # Daily at 2 AM
      retention_days: 30
      storage_location: "s3://example-backup/ai-assistant"
    restore:
      verification: true
      max_age_hours: 24

# Performance tuning
performance:
  thread_pool:
    core_size: 50
    max_size: 200
    queue_size: 1000
    keep_alive_seconds: 60
  connection_pool:
    max_total: 200
    max_idle: 50
    min_idle: 10
    test_on_borrow: true
    test_while_idle: true
  rate_limiting:
    global_rps: 1000
    per_ip_rps: 20
  resource_limits:
    cpu_threshold: 85
    memory_threshold: 85
    disk_threshold: 90
  adaptive_scaling:
    enabled: true
    scale_up_threshold: 80
    scale_down_threshold: 30
    cooldown_seconds: 300
  request_prioritization:
    enabled: true
    priority_queues: 3
  caching:
    response_cache_ttl: 60  # seconds
    shared_cache: true
    use_cache_tags: true

# Production deployment info
deployment:
  regions:
    - name: "us-east"
      primary: true
    - name: "eu-west"
      primary: false
    - name: "ap-southeast"
      primary: false
  update_strategy: "rolling"  # rolling, blue-green, canary
  canary:
    percentage: 10
    evaluation_period: 3600  # 1 hour
    metrics:
      - "error_rate"
      - "latency_p95"
  auto_scaling:
    enabled: true
    min_replicas: 3
    max_replicas: 20
    target_cpu_utilization: 70
    target_memory_utilization: 70
  health_probes:
    liveness:
      path: "/health/live"
      initial_delay_seconds: 30
      period_seconds: 10
      timeout_seconds: 5
      failure_threshold: 3
    readiness:
      path: "/health/ready"
      initial_delay_seconds: 30
      period_seconds: 10
      timeout_seconds: 5
      success_threshold: 1
      failure_threshold: 3
  maintenance_window:
    day: "Sunday"
    hour: 2  # 2 AM UTC
    duration_minutes: 120
