# =========================================================
# AI Assistant Staging Configuration
# =========================================================
# Author: Drmusab
# Last Modified: 2025-07-05 11:31:23
# Environment: Staging
# =========================================================

# Environment settings
environment:
  name: "staging"
  debug: false
  verbose_logging: false
  hot_reload: false
  development_mode: false
  local_execution: false

# Core system settings
system:
  version: "1.0.0"
  instance_id: "staging-instance-${HOSTNAME:-staging}"
  max_concurrent_tasks: 20
  timezone: "UTC"
  temp_directory: "/tmp/ai_assistant"
  data_directory: "/var/lib/ai_assistant"
  startup_timeout: 90  # seconds
  shutdown_timeout: 60  # seconds
  auto_recovery: true
  graceful_shutdown: true

# Core engine configuration
core_engine:
  default_processing_mode: "asynchronous"
  max_concurrent_requests: 50
  default_timeout_seconds: 45.0
  enable_real_time_processing: true
  enable_speech_processing: true
  enable_vision_processing: true
  enable_multimodal_fusion: true
  enable_reasoning: true
  enable_learning: true
  default_quality_level: "balanced"
  adaptive_quality: true
  quality_monitoring: true
  working_memory_size: 4000
  context_window_size: 8192
  memory_consolidation_interval: 1200  # 20 minutes
  enable_response_caching: true
  enable_component_caching: true
  cache_ttl_seconds: 1800  # 30 minutes
  require_authentication: true
  enable_authorization: true
  audit_logging: true
  enable_performance_monitoring: true
  enable_profiling: false
  gc_interval_seconds: 600

# Component manager configuration
component_manager:
  auto_discovery: true
  parallel_initialization: true
  health_monitoring: true
  health_check_interval: 60
  auto_restart_failed: true
  max_restart_attempts: 5
  restart_backoff_factor: 2.0
  component_directories:
    - "src/processing"
    - "src/integrations"
    - "src/memory"
    - "src/skills"
    - "src/reasoning"

# Plugin manager configuration
plugins:
  enabled: true
  auto_discovery: true
  auto_discovery_interval: 600  # 10 minutes
  directories:
    - "/var/lib/ai_assistant/plugins"
    - "src/plugins"
  hot_reload: false
  security_validation: true
  max_plugins_per_type: 30
  plugin_timeout: 45
  plugin_memory_limit_mb: 768
  default_security_level: "sandbox"

# Session manager configuration
sessions:
  storage_type: "database"
  max_idle_time: 1800.0  # 30 minutes
  max_session_time: 86400.0  # 24 hours
  cleanup_on_expire: true
  persist_context: true
  enable_clustering: true
  auto_save_interval: 300.0  # 5 minutes
  encryption_enabled: true
  audit_logging: true
  max_sessions_per_node: 2000
  node_id: "staging-node-${HOSTNAME:-1}"

# Workflow orchestrator configuration
workflows:
  enabled: true
  workflow_directory: "/var/lib/ai_assistant/workflows"
  max_concurrent_workflows: 25
  default_timeout: 300  # seconds
  auto_retry_failed: true
  max_retries: 3
  retry_delay: 5  # seconds
  auto_cleanup_completed: true
  max_workflow_history: 500
  auto_generated_workflows: true
  workflow_templates:
    - "conversation"
    - "research"
    - "content_creation"
    - "data_analysis"
    - "customer_support"
    - "onboarding"

# Interactions configuration
interactions:
  max_duration: 1800  # 30 minutes
  default_timeout: 300  # 5 minutes
  enable_real_time: true
  enable_streaming: true
  max_conversation_history: 200
  default_interaction_mode: "conversational"
  default_input_modalities:
    - "text"
  default_output_modalities:
    - "text"
  auto_detect_modalities: true
  save_interaction_history: true

# Integration configurations
integrations:
  # LLM providers
  llm:
    default_provider: "openai"  # ollama, openai, deepseek
    model_router:
      enabled: true
      strategy: "balanced"  # cost_effective, performance, quality, balanced
      timeout: 45  # seconds
      auto_fallback: true
    ollama:
      enabled: true
      endpoint: "http://ollama-service:11434"
      models:
        - name: "llama3"
          context_size: 8192
          default: false
        - name: "mistral"
          context_size: 4096
          default: true
        - name: "codellama"
          context_size: 16384
      timeout: 60
    openai:
      enabled: true
      api_key: "${OPENAI_API_KEY}"
      organization_id: "${OPENAI_ORG_ID}"
      models:
        - name: "gpt-4"
          context_size: 8192
          default: true
        - name: "gpt-3.5-turbo"
          context_size: 4096
          default: false
      timeout: 60
    deepseek:
      enabled: true
      api_key: "${DEEPSEEK_API_KEY}"
      models:
        - name: "deepseek-chat"
          context_size: 4096
          default: false
      timeout: 60

  # Cache configuration
  cache:
    strategy: "hybrid"  # local, redis, hybrid
    ttl: 1800  # 30 minutes
    max_size_mb: 4096
    enable_compression: true
    redis:
      enabled: true
      host: "redis-cache"
      port: 6379
      password: "${REDIS_PASSWORD}"
      db: 0
      key_prefix: "ai_assistant_staging"
    local:
      enabled: true
      directory: "/var/lib/ai_assistant/cache"
      max_entries: 50000
      eviction_policy: "lru"  # lru, lfu, fifo

  # Database configuration
  database:
    enabled: true
    type: "postgres"  # sqlite, postgres
    sqlite:
      path: "/var/lib/ai_assistant/database/staging.db"
    postgres:
      host: "postgres-db"
      port: 5432
      username: "aiassistant"
      password: "${DB_PASSWORD}"
      database: "aiassistant_staging"
    connection_pool: 20
    timeout: 30
    auto_migrate: true

  # External APIs
  external_apis:
    web_search:
      enabled: true
      provider: "bing"  # dummy, bing, google
      api_key: "${SEARCH_API_KEY}"
      results_per_query: 8
      timeout: 15
    weather:
      enabled: true
      provider: "openweathermap"  # dummy, openweathermap
      api_key: "${WEATHER_API_KEY}"
      timeout: 10
    calendar:
      enabled: true
      provider: "google"  # dummy, google
      client_id: "${CALENDAR_CLIENT_ID}"
      client_secret: "${CALENDAR_CLIENT_SECRET}"
      timeout: 15

# API configurations
api:
  enabled: true
  # REST API configuration
  rest:
    enabled: true
    host: "0.0.0.0"
    port: 8000
    debug: false
    prefix: "/api/v1"
    swagger: true
    middleware:
      cors:
        enabled: true
        allow_origins: ["https://*.example.com", "https://staging.example.com"]
        allow_methods: ["GET", "POST", "PUT", "DELETE", "OPTIONS"]
      rate_limiter:
        enabled: true
        max_requests: 200
        window_seconds: 60
      compression:
        enabled: true
        level: 5
      auth:
        enabled: true
        jwt_secret: "${JWT_SECRET}"
        token_expiry: 86400  # 24 hours

  # WebSocket API configuration
  websocket:
    enabled: true
    host: "0.0.0.0"
    port: 8001
    path: "/ws"
    heartbeat_interval: 30
    max_connections: 2000
    max_message_size: 5242880  # 5MB

  # GraphQL API configuration
  graphql:
    enabled: true
    host: "0.0.0.0"
    port: 8002
    path: "/graphql"
    playground: true
    debug: false

  # gRPC API configuration
  grpc:
    enabled: true
    host: "0.0.0.0"
    port: 50051
    max_workers: 20
    reflection: true

# Memory configurations
memory:
  vector_store:
    type: "postgres"  # local, redis, postgres
    dimension: 1536
    metric: "cosine"  # cosine, euclidean, dot
    index_path: "/var/lib/ai_assistant/vector_indices"
  working_memory:
    max_size: 4000
    ttl_seconds: 1800
  episodic_memory:
    max_episodes: 100000
    consolidation_interval: 1800  # 30 minutes
  semantic_memory:
    enabled: true
    auto_learn: true
  context_window:
    size: 8192
    overlap: 200
  cache:
    enabled: true
    ttl_seconds: 1800
    max_size_mb: 2048

# Skills configurations
skills:
  auto_discovery: true
  skill_directories:
    - "src/skills/builtin"
    - "src/skills/custom"
    - "/var/lib/ai_assistant/skills"
  validate_skills: true
  skill_timeout: 45
  max_skill_memory_mb: 512
  composition:
    enabled: true
    max_composition_depth: 5
  development_mode: false
  default_skills:
    - "conversation"
    - "search"
    - "calculator"
    - "summarization"
    - "translation"
    - "knowledge_base"
    - "content_generation"
    - "data_visualization"

# Processing configurations
processing:
  # Natural language processing
  natural_language:
    default_language: "en"
    intent_threshold: 0.75
    sentiment_analysis: true
    entity_extraction: true
    language_detection: true
    tokenizer: "default"
    max_tokens: 8192

  # Speech processing
  speech:
    enabled: true
    default_quality: "balanced"  # fast, balanced, quality
    model_path: "/var/lib/ai_assistant/models/speech"
    audio_sample_rate: 16000
    use_gpu: true
    emotion_detection: true
    speaker_recognition: true
    cache_transcriptions: true

  # Vision processing
  vision:
    enabled: true
    model_path: "/var/lib/ai_assistant/models/vision"
    default_resolution: "medium"  # low, medium, high
    use_gpu: true
    detect_faces: true
    detect_objects: true
    ocr_enabled: true
    cache_results: true

  # Multimodal processing
  multimodal:
    enabled: true
    fusion_strategy: "weighted"  # early, late, weighted
    cross_modal_attention: true
    modality_weights:
      text: 0.5
      speech: 0.3
      vision: 0.2

# Reasoning configurations
reasoning:
  enabled: true
  logic_engine:
    max_depth: 8
    timeout: 45
  knowledge_graph:
    enabled: true
    path: "/var/lib/ai_assistant/knowledge_base/graphs"
    auto_update: true
  planning:
    enabled: true
    max_steps: 15
    goal_decomposition: true
  decision_making:
    confidence_threshold: 0.75
    uncertainty_handling: true
    decision_tree:
      max_depth: 8

# Learning configurations
learning:
  enabled: true
  continual_learning:
    enabled: true
    update_interval: 7200  # 2 hours
    batch_size: 128
    learning_rate: 0.001
  preference_learning:
    enabled: true
    adaptation_rate: 0.1
  feedback_processing:
    enabled: true
    incorporate_feedback: true
  model_adaptation:
    enabled: true
    fine_tuning: true

# Observability configurations
observability:
  # Logging
  logging:
    level: "INFO"
    format: "json"  # simple, detailed, json
    console_output: false
    file_output: true
    log_directory: "/var/log/ai_assistant"
    max_log_size_mb: 500
    max_log_files: 30
    trace_enabled: true
    sanitize_sensitive_data: true
    custom_handlers:
      rotation:
        enabled: true
        when: "midnight"
        interval: 1
        backup_count: 14

  # Monitoring
  monitoring:
    enabled: true
    metrics:
      enabled: true
      export: true
      port: 8003
      path: "/metrics"
    tracing:
      enabled: true
      exporter: "jaeger"  # console, jaeger
      jaeger_endpoint: "http://jaeger:14268/api/traces"
    alerting:
      enabled: true
      threshold_cpu_percent: 75
      threshold_memory_percent: 75
      threshold_error_rate: 0.03
    dashboards:
      enabled: true
      refresh_interval: 60

  # Profiling
  profiling:
    enabled: true
    cpu_profiling: true
    memory_profiling: true
    gpu_profiling: true
    profile_directory: "/var/lib/ai_assistant/profiles"
    interval: 900  # 15 minutes

# Security configurations
security:
  # Authentication
  authentication:
    enabled: true
    providers:
      - "local"
      - "oauth"
    local:
      user_db_path: "/var/lib/ai_assistant/users.db"
    oauth:
      google:
        enabled: true
        client_id: "${GOOGLE_OAUTH_CLIENT_ID}"
        client_secret: "${GOOGLE_OAUTH_CLIENT_SECRET}"
      github:
        enabled: true
        client_id: "${GITHUB_OAUTH_CLIENT_ID}"
        client_secret: "${GITHUB_OAUTH_CLIENT_SECRET}"
    session_timeout: 86400  # 24 hours
    max_failed_attempts: 5
    token_secret: "${JWT_SECRET}"

  # Authorization
  authorization:
    enabled: true
    rbac_enabled: true
    default_role: "user"
    roles:
      - name: "admin"
        permissions: ["*"]
      - name: "user"
        permissions: ["read", "execute", "create"]
      - name: "guest"
        permissions: ["read", "execute_limited"]

  # Encryption
  encryption:
    enabled: true
    algorithm: "AES-256-GCM"
    key_rotation: true
    key_path: "/var/lib/ai_assistant/keys"

  # Sanitization
  sanitization:
    enabled: true
    sanitize_inputs: true
    sanitize_outputs: true
    allowed_html_tags: ["b", "i", "code", "pre", "a", "ul", "ol", "li"]

# Staging specific settings
staging:
  test_accounts:
    - username: "staging_admin"
      password: "${STAGING_ADMIN_PASSWORD}"
      role: "admin"
    - username: "staging_user"
      password: "${STAGING_USER_PASSWORD}"
      role: "user"
    - username: "staging_guest"
      password: "${STAGING_GUEST_PASSWORD}"
      role: "guest"
  feature_flags:
    enable_beta_features: true
    load_testing_enabled: true
    synthetic_monitoring: true
    canary_deployments: true
  testing:
    automated_tests_enabled: true
    performance_test_enabled: true
    security_scan_enabled: true
    regression_test_enabled: true
  load_testing:
    max_virtual_users: 500
    ramp_up_period: 60
    steady_state_time: 300
    scenarios:
      - name: "basic_conversation"
        weight: 50
      - name: "complex_workflow"
        weight: 30
      - name: "multimodal_processing"
        weight: 20
  monitoring:
    ping_interval: 60
    health_check_endpoints:
      - path: "/health"
        expected_status: 200
      - path: "/api/v1/status"
        expected_status: 200
    synthetic_monitors:
      - name: "basic_conversation"
        interval: 300
      - name: "search_functionality"
        interval: 600
